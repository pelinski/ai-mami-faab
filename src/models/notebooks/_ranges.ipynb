{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir)))\n",
    "from dataset import Dataset\n",
    "from utils import load_model, get_all_run_ids, get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../trained/transformer-autoencoder-timecomp-jan\"\n",
    "run_ids = get_all_run_ids(path=models_path)\n",
    "device = get_device()\n",
    "models = {}\n",
    "for _id in run_ids:\n",
    "    models[_id] = load_model(_id, path=models_path).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset().load_dataset_from_pickle(pickle_path=\"../../dataset/data/0117/0117_processed_1024.pkl\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:02<00:00, 611.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0daq0g9h max [2.7029311656951904, 2.1502432823181152, 2.322965383529663, 2.1830039024353027] min [-2.581634998321533, -1.9115527868270874, -3.1803038120269775, -2.339738607406616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:03<00:00, 429.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model sys6hs5g max [2.301015615463257, 2.3510663509368896, 1.5381203889846802, 1.894698143005371] min [-2.2298760414123535, -1.7534922361373901, -1.6228348016738892, -1.8588333129882812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:02<00:00, 736.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 8j4cqfd8 max [0.7843466997146606, 0.7664592266082764, 0.8660548329353333, 0.694176971912384] min [-0.8101696372032166, -0.8937942385673523, -0.8518332839012146, -0.7511453628540039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max, min = torch.empty(0).to(\"cpu\"), torch.empty(0).to(\"cpu\")\n",
    "models_range = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _id in run_ids:\n",
    "        model = models[_id]\n",
    "        \n",
    "        _max, _min = torch.empty(0).to(\"cpu\"), torch.empty(0).to(\"cpu\")\n",
    "\n",
    "        for batch_idx, (train_inputs, _) in enumerate(tqdm(dataloader)):\n",
    "            out = model.forward_encoder(train_inputs.to(device)).detach().to(\"cpu\")\n",
    "            \n",
    "            _max = torch.cat((_max, out.max(dim=1).values.max(dim=0).values.unsqueeze(0)), dim=0)\n",
    "            _min = torch.cat((_min, out.min(dim=1).values.min(dim=0).values.unsqueeze(0)), dim=0)\n",
    "            \n",
    "            models_range[_id] = (_max, _min)\n",
    "            \n",
    "        _max = _max.max(dim=0).values     \n",
    "        _min = _min.min(dim=0).values\n",
    "               \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        models_range[_id] = {\"min\":_min.tolist(), \"max\": _max.tolist()}\n",
    "        \n",
    "        print(\"model\", _id, \"max\", _max.tolist(), \"min\", _min.tolist())\n",
    "            \n",
    "        max = torch.cat((max, _max.unsqueeze(0)), dim=0)\n",
    "        min = torch.cat((min, _min.unsqueeze(0)), dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0daq0g9h': {'min': [-2.581634998321533,\n",
       "   -1.9115527868270874,\n",
       "   -3.1803038120269775,\n",
       "   -2.339738607406616],\n",
       "  'max': [2.7029311656951904,\n",
       "   2.1502432823181152,\n",
       "   2.322965383529663,\n",
       "   2.1830039024353027]},\n",
       " 'sys6hs5g': {'min': [-2.2298760414123535,\n",
       "   -1.7534922361373901,\n",
       "   -1.6228348016738892,\n",
       "   -1.8588333129882812],\n",
       "  'max': [2.301015615463257,\n",
       "   2.3510663509368896,\n",
       "   1.5381203889846802,\n",
       "   1.894698143005371]},\n",
       " '8j4cqfd8': {'min': [-0.8101696372032166,\n",
       "   -0.8937942385673523,\n",
       "   -0.8518332839012146,\n",
       "   -0.7511453628540039],\n",
       "  'max': [0.7843466997146606,\n",
       "   0.7664592266082764,\n",
       "   0.8660548329353333,\n",
       "   0.694176971912384]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../models/trained/transformer-autoencoder-timecomp-jan/models_range.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/json/__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "with open(\"../../models/trained/transformer-autoencoder-timecomp-jan/models_range.json\", \"wb\") as f:\n",
    "    json.dump(models_range, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faab-uzUOpGyK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
