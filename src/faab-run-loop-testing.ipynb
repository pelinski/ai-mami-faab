{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# faab-run-loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch \n",
        "from pybela import Streamer\n",
        "import json\n",
        "import asyncio\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os \n",
        "\n",
        "from utils import get_device, load_config, load_model, get_all_run_ids\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "device = get_device()\n",
        "\n",
        "path =\"models/trained\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## run-loop testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mConnection successful\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vars = ['gFaabSensor_1', 'gFaabSensor_2', 'gFaabSensor_3', 'gFaabSensor_4', 'gFaabSensor_5', 'gFaabSensor_6', 'gFaabSensor_7', 'gFaabSensor_8']\n",
        "streamer = Streamer()\n",
        "streamer.connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_id = \"02emtq9d\"\n",
        "model = load_model(_id, path=path)\n",
        "seq_len = 512\n",
        "\n",
        "async def callback(block):\n",
        "    _raw_data_tensor = torch.stack([torch.FloatTensor(buffer[\"buffer\"][\"data\"]) for buffer in block]) # num_features, 1024\n",
        "    inputs = _raw_data_tensor.unfold(1, seq_len, seq_len).permute(1,2,0) # n, seq_len, num_features  \n",
        "    \n",
        "    for _input in inputs:\n",
        "        out = model(_input.to(device)).permute(1,0) # num_features, seq_len\n",
        "        for idx,feature in enumerate(out):\n",
        "            streamer.send_buffer(idx, 'f', seq_len, feature.tolist(), verbose=True)\n",
        "            \n",
        "streamer.start_streaming(vars, on_block_callback=callback)\n",
        "asyncio.run(asyncio.sleep(10))\n",
        "streamer.stop_streaming()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## models params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ff_size</th>\n",
              "      <th>num_heads</th>\n",
              "      <th>num_layers</th>\n",
              "      <th>learning_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abor4fs6</th>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qcamd717</th>\n",
              "      <td>256</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3r3rbr3q</th>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ggnxfugo</th>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qba7ejlo</th>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2kqwwsar</th>\n",
              "      <td>128</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ejdzc3ym</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24jf630m</th>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jeixb37n</th>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u0ahkjvo</th>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ff_size  num_heads  num_layers  learning_rate\n",
              "abor4fs6       32          2           1       0.000516\n",
              "qcamd717      256          2           8       0.000112\n",
              "3r3rbr3q      256          1           7       0.000168\n",
              "ggnxfugo      256          1           7       0.000842\n",
              "qba7ejlo       16          4           3       0.000149\n",
              "2kqwwsar      128          4           6       0.000466\n",
              "ejdzc3ym       64          2           7       0.000850\n",
              "24jf630m       64          4           7       0.000105\n",
              "jeixb37n        8          4           6       0.000838\n",
              "u0ahkjvo       32          4           7       0.000797"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_ids = get_all_run_ids(path=path)\n",
        "params = [\"ff_size\", \"num_heads\", \"num_layers\", \"learning_rate\"]\n",
        "_id_config = {}\n",
        "\n",
        "for _id in run_ids:\n",
        "    _id_config[_id] = {key: load_config(_id, path=path)[key] for key in params}\n",
        "    \n",
        "df = pd.DataFrame.from_dict(_id_config, orient='index')\n",
        "df.head(10)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### scale to values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'ff_size': [8, 16, 32, 64, 128, 256],\n",
              "  'num_heads': [1, 2, 4],\n",
              "  'num_layers': [1, 2, 3, 4, 5, 6, 7, 8]},\n",
              " {'ff_size': {8: 0.0, 16: 0.2, 32: 0.4, 64: 0.6, 128: 0.8, 256: 1.0},\n",
              "  'num_heads': {1: 0.0, 2: 0.5, 4: 1.0},\n",
              "  'num_layers': {1: 0.0,\n",
              "   2: 0.14285714285714285,\n",
              "   3: 0.2857142857142857,\n",
              "   4: 0.42857142857142855,\n",
              "   5: 0.5714285714285714,\n",
              "   6: 0.7142857142857143,\n",
              "   7: 0.8571428571428571,\n",
              "   8: 1.0}})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranges = {\n",
        "    \"ff_size\": [8, 16, 32, 64, 128, 256],\n",
        "    \"num_heads\": [1, 2, 4],\n",
        "    \"num_layers\": [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "}\n",
        "\n",
        "mapped_ranges = {}\n",
        "for key in ranges:\n",
        "    mapped_ranges[key] = {value: idx /(len(ranges[key])-1) for idx, value in enumerate(ranges[key])}\n",
        "\n",
        "ranges, mapped_ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ff_size</th>\n",
              "      <th>num_heads</th>\n",
              "      <th>num_layers</th>\n",
              "      <th>learning_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abor4fs6</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.516246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qcamd717</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.112486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3r3rbr3q</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.168206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ggnxfugo</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.841713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qba7ejlo</th>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.149064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2kqwwsar</th>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.465967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ejdzc3ym</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.849721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24jf630m</th>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.105182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jeixb37n</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.837599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u0ahkjvo</th>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.797156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ff_size  num_heads  num_layers  learning_rate\n",
              "abor4fs6      0.4        0.5    0.000000       0.516246\n",
              "qcamd717      1.0        0.5    1.000000       0.112486\n",
              "3r3rbr3q      1.0        0.0    0.857143       0.168206\n",
              "ggnxfugo      1.0        0.0    0.857143       0.841713\n",
              "qba7ejlo      0.2        1.0    0.285714       0.149064\n",
              "2kqwwsar      0.8        1.0    0.714286       0.465967\n",
              "ejdzc3ym      0.6        0.5    0.857143       0.849721\n",
              "24jf630m      0.6        1.0    0.857143       0.105182\n",
              "jeixb37n      0.0        1.0    0.714286       0.837599\n",
              "u0ahkjvo      0.4        1.0    0.857143       0.797156"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_functions = {\n",
        "    \"ff_size\": lambda x: mapped_ranges[\"ff_size\"][x],\n",
        "    \"num_heads\": lambda x: mapped_ranges[\"num_heads\"][x],\n",
        "    \"num_layers\": lambda x:mapped_ranges[\"num_layers\"][x],\n",
        "    \"learning_rate\": lambda x: x*1000\n",
        "}\n",
        "\n",
        "\n",
        "# Apply a different function to each column\n",
        "df_scaled = df.copy()\n",
        "for column, func in column_functions.items():\n",
        "    if column in df_scaled.columns:\n",
        "        df_scaled[column] = df_scaled[column].apply(func)\n",
        "        \n",
        "df_scaled.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaled_model_coordinates = df_scaled.to_numpy()\n",
        "scaled_model_coordinates.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import get_scaled_params\n",
        "scaled_model_coordinates = get_scaled_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import find_closest_model\n",
        "import numpy as np\n",
        "vector = np.array([0.1, 0.2, 0.3, 0.4])  # Replace with your actual vector\n",
        "\n",
        "find_closest_model(vector, scaled_model_coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(scaled_model_coordinates.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "test the scaling (assumes model output to be between 0 and 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector = np.array([0.1, 0.2, 0.3, 0.4])  # Replace with your actual vector\n",
        "\n",
        "# Calculate the Euclidean distances\n",
        "distances = np.linalg.norm(scaled_model_coordinates - vector, axis=1)\n",
        "\n",
        "# Find the index of the row with the smallest distance\n",
        "closest_row_index = np.argmin(distances)\n",
        "\n",
        "# Closest row\n",
        "closest_row = scaled_model_coordinates[closest_row_index]\n",
        "\n",
        "print(closest_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a figure and a grid of subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
        "\n",
        "# Flatten the axes array for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, column in enumerate(df_scaled.columns):\n",
        "    sns.histplot(df_scaled[column], ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of Values for {column}')\n",
        "    axes[i].set_xlabel(column)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "\n",
        "# Hide any unused axes if the number of columns is odd\n",
        "if len(df_scaled.columns) % 2 != 0:\n",
        "    axes[-1].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## loop with feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_id = \"02emtq9d\"\n",
        "model = load_model(_id)\n",
        "seq_len = 512\n",
        "num_blocks_to_compute_avg = 10\n",
        "avg = []\n",
        "async def callback(block):\n",
        "    _raw_data_tensor = torch.stack([torch.FloatTensor(buffer[\"buffer\"][\"data\"]) for buffer in block]) # num_features, 1024\n",
        "    # split the data into seq_len to feed it into the model\n",
        "    inputs = _raw_data_tensor.unfold(1, seq_len, seq_len).permute(1,2,0) # n, seq_len, num_features  \n",
        "    \n",
        "    # for each sequence of seq_len, feed it into the model\n",
        "    for _input in inputs:\n",
        "        out = model.forward_encoder(_input.to(device)).permute(1,0) # num_outputs, seq_len\n",
        "        \n",
        "        for idx,feature in enumerate(out): # send each feature to Bela\n",
        "            streamer.send_buffer(idx, 'f', seq_len, feature.tolist(), verbose=True)\n",
        "            \n",
        "        avg.append(out.mean(dim=1))\n",
        "   \n",
        "    if len(avg) == num_blocks_to_compute_avg:\n",
        "        avg_tensor = torch.stack(avg) # num_blocks, num_features\n",
        "        avg_tensor = avg_tensor.mean(dim=0).numpy() # num_features\n",
        "        \n",
        "        # Calculate the Euclidean distances\n",
        "        distances = np.linalg.norm(scaled_model_coordinates - avg_tensor, axis=1)\n",
        "\n",
        "        # Find the index of the row with the smallest distance\n",
        "        closest_row_index = np.argmin(distances)\n",
        "\n",
        "        # Closest row\n",
        "        closest_row = scaled_model_coordinates[closest_row_index]\n",
        "\n",
        "        print(avg_tensor, closest_row)\n",
        "        avg.clear()\n",
        "        \n",
        "streamer.start_streaming(vars, on_block_callback=callback)\n",
        "asyncio.run(asyncio.sleep(10))\n",
        "streamer.stop_streaming()\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
