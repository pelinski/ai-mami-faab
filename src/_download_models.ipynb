{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "from utils import _scale_params, load_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "# faab_autoencoder_transformer/frraprup -- transformer\n",
    "# faab_autoencoder_transformer_time/ehdzqdop -- transformer time\n",
    "sweep = api.sweep(\"teresapelinski/faab_autoencoder_transformer_time/ehdzqdop\")\n",
    "\n",
    "_path = \"models/trained/transformer-autoencoder-time\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_runs = []\n",
    "\n",
    "# Iterate over runs in the sweep\n",
    "for run in sweep.runs:\n",
    "    # Fetch the run to get detailed information, including its state\n",
    "    detailed_run = wandb.Api().run(f\"{run.project}/{run.id}\")\n",
    "    # Check if the run is finished\n",
    "    if detailed_run.state == \"finished\":\n",
    "        finished_runs.append(detailed_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sw in finished_runs:\n",
    "    root_file_name = f'transformer_run_{sw.id}_500'\n",
    "    sw.file(f'{root_file_name}.model').download(root=_path, exist_ok=True)\n",
    "    json.dump(sw.config, open(f'{_path}/{root_file_name}.json', \"w\"))\n",
    "    json.dump({\"train_loss\": sw.summary[\"train_loss\"]}, open(f'{_path}/{root_file_name}_metrics.json', \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = []\n",
    "for sw in finished_runs:\n",
    "    run_ids.append(sw.id)\n",
    "json.dump(run_ids, open(f'{_path}/run_ids.json', \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_losses = {}\n",
    "for _id in run_ids:\n",
    "    _train_losses[_id] = json.load(open(f'{_path}/transformer_run_{_id}_500_metrics.json'))[\"train_loss\"]\n",
    "\n",
    "models_ordered_by_asc_loss = list(dict(sorted(_train_losses.items(), key=lambda item: item[1])).keys())\n",
    "filename = _path + \"/models_ordered_by_asc_loss.json\"\n",
    "\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(models_ordered_by_asc_loss, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4dxvf5pw': [0.4, 0.5, 0.8571428571428571, 0.7421047694869691],\n",
       " 'tvbizxw2': [0.8, 0.5, 0.0, 0.2618658728172881],\n",
       " '9z330h5w': [0.6, 0.5, 0.14285714285714285, 0.1887596764955175],\n",
       " 'h61hlj64': [0.4, 0.5, 0.14285714285714285, 0.03746204794216246],\n",
       " '8wo1aq41': [1.0, 0.0, 0.7142857142857143, 0.040887520403775524],\n",
       " '4b32v3ec': [1.0, 0.5, 0.8571428571428571, 0.6928346915235627],\n",
       " 'gre5ffx7': [0.6, 0.5, 0.7142857142857143, 0.32916969292967224],\n",
       " 'ca5q1w6h': [1.0, 0.0, 0.5714285714285714, 0.2312109168257446],\n",
       " 's6l7qpnc': [0.6, 1.0, 0.0, 0.9309163658921189],\n",
       " '9g79o4ch': [0.0, 1.0, 1.0, 0.31511971752569],\n",
       " 'w872lqzg': [0.6, 1.0, 0.0, 0.9747724262764154]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_model_coordinates = _scale_params(path = _path)\n",
    "\n",
    "filename = _path + \"/scaled_params.json\"\n",
    "with open (filename, 'w') as file:\n",
    "    json.dump(scaled_model_coordinates, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_configs = {}\n",
    "for run in finished_runs:\n",
    "    config = load_config(run.id, path=_path)\n",
    "    all_configs[run.id] = config\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4dxvf5pw': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.1755480781713537,\n",
       "  'ff_size': 32,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 2,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 128,\n",
       "  'num_layers': 7,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 128,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0007421047694869691,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " 'tvbizxw2': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.2747677085289542,\n",
       "  'ff_size': 128,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 2,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 64,\n",
       "  'num_layers': 1,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 64,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.00026186587281728813,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " '9z330h5w': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.21998168955480585,\n",
       "  'ff_size': 64,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 2,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 256,\n",
       "  'num_layers': 2,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 128,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0001887596764955175,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " 'h61hlj64': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.15957748127327462,\n",
       "  'ff_size': 32,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 2,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 256,\n",
       "  'num_layers': 2,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 64,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 3.7462047942162455e-05,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " '8wo1aq41': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.16841083761626505,\n",
       "  'ff_size': 256,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 1,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 128,\n",
       "  'num_layers': 6,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 128,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 4.088752040377552e-05,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " '4b32v3ec': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.10523071664836035,\n",
       "  'ff_size': 256,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 2,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 64,\n",
       "  'num_layers': 7,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 128,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0006928346915235627,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " 'gre5ffx7': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.11632287516895357,\n",
       "  'ff_size': 64,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 2,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 256,\n",
       "  'num_layers': 6,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 32,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0003291696929296722,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " 'ca5q1w6h': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.24701480836259773,\n",
       "  'ff_size': 256,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 1,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 256,\n",
       "  'num_layers': 5,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 64,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0002312109168257446,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " 's6l7qpnc': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.13814190289021755,\n",
       "  'ff_size': 64,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 4,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 64,\n",
       "  'num_layers': 1,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 128,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0009309163658921189,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " '9g79o4ch': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.11107290875785364,\n",
       "  'ff_size': 8,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 4,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 256,\n",
       "  'num_layers': 8,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 64,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.00031511971752569,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0},\n",
       " 'w872lqzg': {'mask': False,\n",
       "  'pred': False,\n",
       "  'model': 'transformer',\n",
       "  'device': 'cuda:0',\n",
       "  'epochs': 500,\n",
       "  'dropout': 0.28173647120113715,\n",
       "  'ff_size': 64,\n",
       "  'project': 'faab_autoencoder_transformer_time',\n",
       "  'seq_len': 1024,\n",
       "  'feat_len': 8,\n",
       "  'num_heads': 4,\n",
       "  'optimizer': 'rmsprop',\n",
       "  'batch_size': 32,\n",
       "  'num_layers': 1,\n",
       "  'pickle_path': '07041536_processed_1024_overlap.pkl',\n",
       "  'comp_seq_len': 128,\n",
       "  'comp_feat_len': 4,\n",
       "  'learning_rate': 0.0009747724262764154,\n",
       "  'max_grad_norm': 0,\n",
       "  'pe_scale_factor': 1,\n",
       "  'plotter_samples': 5,\n",
       "  'scheduler_gamma': 0.1,\n",
       "  'num_encoder_layers': 7,\n",
       "  'scheduler_step_size': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faab-ECLAI4QK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
