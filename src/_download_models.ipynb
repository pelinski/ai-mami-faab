{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import json\n",
        "from utils import _scale_params, load_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "api.entity = \"teresapelinski\"\n",
        "# faab_autoencoder_transformer/frraprup -- transformer\n",
        "# faab_autoencoder_transformer_time/ehdzqdop -- transformer time\n",
        "\n",
        "sweep_ids = [\"qzxosicp\", \"5dcv1tkh\", \"w59yusdc\", \"i9rlauv6\"]\n",
        "sweeps = [api.sweep(f'teresapelinski/faab_autoencoder_transformer_jan/{sweep}') for sweep in sweep_ids]\n",
        "\n",
        "_path = \"models/trained/transformer-autoencoder-jan\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# finished_runs = []\n",
        "\n",
        "# # Iterate over runs in the sweep\n",
        "# for run in sweep.runs:\n",
        "#     # Fetch the run to get detailed information, including its state\n",
        "#     detailed_run = wandb.Api().run(f\"{run.project}/{run.id}\")\n",
        "#     # Check if the run is finished\n",
        "#     if detailed_run.state == \"finished\":\n",
        "#         finished_runs.append(detailed_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# #load api key from .env\n",
        "# with open(\"../.env\") as f:\n",
        "#     for line in f:\n",
        "#         if line.strip() and not line.startswith('#'):\n",
        "#             key, value = line.strip().split('=', 1)\n",
        "#             os.environ[key] = value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.login(key=os.environ[\"WANDB_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pctbsiqi 50\n",
            "o8jxyrj5 50\n",
            "ymdetlr8 400\n",
            "i4wfl4b4 50\n",
            "vyfy7lha 300\n",
            "7aziw3nx 100\n",
            "6cj4c36w 100\n",
            "8d2mwki4 250\n",
            "siflj6dk 100\n",
            "omaoac63 50\n",
            "senl8hn1 50\n",
            "fc4x5bsx 50\n",
            "746wz0w1 50\n",
            "9b9pjlgs 50\n",
            "2swzga0k 50\n"
          ]
        }
      ],
      "source": [
        "id_ep = {}\n",
        "run_ids = []\n",
        "for sweep in sweeps:\n",
        "    for run in sweep.runs:\n",
        "        files = [file.name for file in run.files()]\n",
        "        matching_files = [file for file in files if file.endswith(\".model\")]\n",
        "        epochs = [int(file.split(\"_\")[-1].split(\".model\")[0]) for file in matching_files]\n",
        "        if epochs == []:\n",
        "            continue\n",
        "        highest_epoch = max(epochs)\n",
        "        id_ep[run.id] = highest_epoch\n",
        "        run_ids.append(run.id)\n",
        "        print(run.id, highest_epoch)    \n",
        "        root_file_name = f'transformer_run_{run.id}_{highest_epoch}'\n",
        "        run.file(f'{root_file_name}.model').download(root=_path, exist_ok=True)\n",
        "        json.dump(run.config, open(f'{_path}/{root_file_name}.json', \"w\"))\n",
        "        json.dump({\"train_loss\": run.summary[\"train_loss\"]}, open(f'{_path}/{root_file_name}_metrics.json', \"w\"))\n",
        "\n",
        "json.dump(run_ids, open(f'{_path}/run_ids.json', \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "json.dump(id_ep, open(f'{_path}/id_ep.json', \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "_train_losses = {}\n",
        "for _id in run_ids:\n",
        "    _train_losses[_id] = json.load(open(f'{_path}/transformer_run_{_id}_{id_ep[_id]}_metrics.json'))[\"train_loss\"]\n",
        "\n",
        "models_ordered_by_asc_loss = list(dict(sorted(_train_losses.items(), key=lambda item: item[1])).keys())\n",
        "filename = _path + \"/models_ordered_by_asc_loss.json\"\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(models_ordered_by_asc_loss, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaled_model_coordinates = _scale_params(epochs=id_ep, path = _path)\n",
        "\n",
        "filename = _path + \"/scaled_params.json\"\n",
        "with open (filename, 'w') as file:\n",
        "    json.dump(scaled_model_coordinates, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_configs = {}\n",
        "for run in run_ids:\n",
        "    config = load_config(run, epochs=id_ep[run],path=_path)\n",
        "    all_configs[run] = config\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pctbsiqi': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1063194129932942,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0009264214716724124,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'o8jxyrj5': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.23331482516224167,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.00015227127048295398,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'ymdetlr8': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14314017749000166,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'num_layers': 6,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0002778439284384158,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'i4wfl4b4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.17777293311092132,\n",
              "  'ff_size': 64,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0008496110430420494,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'vyfy7lha': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.24472859066289632,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0009493400066035924,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '7aziw3nx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1543240731758888,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 8,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0006073482604437436,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '6cj4c36w': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2943067401460615,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 7,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0005759742905794555,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '8d2mwki4': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.21859738039014048,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.000819966081706723,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'siflj6dk': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1903504949149019,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0009186067474290544,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'omaoac63': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.2557846451883087,\n",
              "  'ff_size': 256,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'num_layers': 2,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.0008163673968628799,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'senl8hn1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.20514296263695397,\n",
              "  'ff_size': 8,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'sgd',\n",
              "  'batch_size': 64,\n",
              "  'num_layers': 3,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.000846646416065111,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " 'fc4x5bsx': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.26155446607297794,\n",
              "  'ff_size': 16,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'sgd',\n",
              "  'batch_size': 64,\n",
              "  'num_layers': 5,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.00046771898857087734,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '746wz0w1': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.13985150718501038,\n",
              "  'ff_size': 32,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'num_heads': 2,\n",
              "  'optimizer': 'adam',\n",
              "  'batch_size': 32,\n",
              "  'num_layers': 4,\n",
              "  'pickle_path': '0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'learning_rate': 0.00023838122588516075,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '9b9pjlgs': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.1936871581847438,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 1,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0117/0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0117/weights.pkl',\n",
              "  'learning_rate': 0.0005394062093786062,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0},\n",
              " '2swzga0k': {'mask': False,\n",
              "  'pred': False,\n",
              "  'model': 'transformer',\n",
              "  'device': 'cuda:0',\n",
              "  'epochs': 500,\n",
              "  'd_model': 4,\n",
              "  'dropout': 0.14810441591878423,\n",
              "  'ff_size': 128,\n",
              "  'project': 'faab_autoencoder_transformer',\n",
              "  'seq_len': 1024,\n",
              "  'criterion': 'weighted_mse',\n",
              "  'num_heads': 4,\n",
              "  'optimizer': 'rmsprop',\n",
              "  'batch_size': 64,\n",
              "  'num_layers': 1,\n",
              "  'pickle_path': 'src/dataset/data/0117/0117_processed_1024.pkl',\n",
              "  'feat_in_size': 8,\n",
              "  'weights_path': 'src/dataset/data/0117/weights.pkl',\n",
              "  'learning_rate': 0.000671571579135955,\n",
              "  'max_grad_norm': 0,\n",
              "  'pe_scale_factor': 1,\n",
              "  'plotter_samples': 5,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_encoder_layers': 7,\n",
              "  'scheduler_step_size': 0}}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "faab-uzUOpGyK",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
