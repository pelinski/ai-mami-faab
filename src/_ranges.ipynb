{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model, get_all_run_ids, get_device\n",
    "from dataset import Dataset\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/trained/transformer-autoencoder-jan\"\n",
    "run_ids = get_all_run_ids(path=models_path)\n",
    "device = get_device()\n",
    "models = {}\n",
    "for _id in run_ids:\n",
    "    models[_id] = load_model(_id, path=models_path).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset().load_dataset_from_pickle(pickle_path=\"dataset/data/0117/0117_processed_1024.pkl\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:28<00:00, 56.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model pctbsiqi max [1.6746190786361694, 0.07133796066045761, 1.26933753490448, 0.0012228247942402959] min [-1.3958884477615356, -0.6594092845916748, -1.3863295316696167, 0.00026616296963766217]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [01:33<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model o8jxyrj5 max [1.6372580528259277, 1.747969150543213, 1.2924197912216187, 1.519474744796753] min [-1.8232892751693726, -1.7502270936965942, -1.6060312986373901, -0.9402924180030823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:35<00:00, 45.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ymdetlr8 max [1.31331467628479, 0.7224118113517761, 1.5972239971160889, 0.1701325923204422] min [-1.5534520149230957, -0.07537082582712173, -1.4862853288650513, -0.9302182793617249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [01:30<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model i4wfl4b4 max [1.6199065446853638, 1.3801569938659668, 0.013666436076164246, 1.355510950088501] min [-1.1120800971984863, -0.9972944855690002, -0.5565490126609802, -0.45933181047439575]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:22<00:00, 72.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model vyfy7lha max [0.9865561723709106, 0.23190835118293762, 0.9161754250526428, 0.9468040466308594] min [-1.6668015718460083, -0.0009262582170777023, -1.7075635194778442, -1.8518742322921753]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [01:18<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 7aziw3nx max [1.1772940158843994, 0.2203264832496643, 0.32889503240585327, 1.2360318899154663] min [-1.541772723197937, -0.008815288543701172, -1.234311580657959, -1.7204748392105103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:40<00:00, 39.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 6cj4c36w max [0.21104083955287933, 0.8396482467651367, 1.3574613332748413, 1.3282206058502197] min [-0.8825191259384155, -0.05352480709552765, -1.6310874223709106, -1.7323819398880005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:28<00:00, 56.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 8d2mwki4 max [1.726462960243225, 1.7417572736740112, 1.6043498516082764, 0.0006538935122080147] min [-0.90981525182724, -0.8965160250663757, -0.856239914894104, -0.350905179977417]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:15<00:00, 105.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model siflj6dk max [0.6747777462005615, 1.5505409240722656, -4.904134766547941e-05, 1.653831958770752] min [-0.06503783166408539, -1.9445329904556274, -0.0006112190894782543, -1.7431806325912476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:29<00:00, 54.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model omaoac63 max [1.6803079843521118, 0.12739428877830505, 1.9200400114059448, 0.8957136869430542] min [-1.8376109600067139, -0.9383289217948914, -1.7438448667526245, -0.11638431996107101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:40<00:00, 40.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model senl8hn1 max [1.1382828950881958, 1.7197128534317017, 1.6995105743408203, 1.720637321472168] min [-1.7098701000213623, -1.7187159061431885, -1.7076935768127441, -1.7145898342132568]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [01:05<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fc4x5bsx max [0.15479649603366852, 1.2426408529281616, 1.715172290802002, 0.18656404316425323] min [-1.6599247455596924, -1.0748488903045654, 0.32284682989120483, -1.034473180770874]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:43<00:00, 37.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 746wz0w1 max [-0.04332290217280388, 1.5731030702590942, 1.6169477701187134, 1.6142486333847046] min [-1.5528682470321655, -1.0895296335220337, -1.1399810314178467, -1.6288503408432007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:08<00:00, 186.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 9b9pjlgs max [0.7907081842422485, 0.9646182656288147, 1.136832594871521, 0.584116518497467] min [-1.2025809288024902, -1.4607346057891846, -1.5762684345245361, -0.8785410523414612]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:15<00:00, 102.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2swzga0k max [0.7010164856910706, 0.6740905046463013, 0.8112685084342957, 0.43762096762657166] min [-1.3454747200012207, -1.053367257118225, -1.2270889282226562, -0.44327738881111145]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/trained/0117/models_range.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 33\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mmax\u001b[39m, _max\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mmin\u001b[39m, _min\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/trained/0117/models_range.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     34\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(models_range, f)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/faab-uzUOpGyK/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/trained/0117/models_range.json'"
     ]
    }
   ],
   "source": [
    "max, min = torch.empty(0).to(\"cpu\"), torch.empty(0).to(\"cpu\")\n",
    "models_range = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _id in run_ids:\n",
    "        model = models[_id]\n",
    "        \n",
    "        _max, _min = torch.empty(0).to(\"cpu\"), torch.empty(0).to(\"cpu\")\n",
    "\n",
    "        for batch_idx, (train_inputs, _) in enumerate(tqdm(dataloader)):\n",
    "            out = model.forward_encoder(train_inputs.to(device)).detach().to(\"cpu\")\n",
    "            \n",
    "            _max = torch.cat((_max, out.max(dim=1).values.max(dim=0).values.unsqueeze(0)), dim=0)\n",
    "            _min = torch.cat((_min, out.min(dim=1).values.min(dim=0).values.unsqueeze(0)), dim=0)\n",
    "            \n",
    "            models_range[_id] = (_max, _min)\n",
    "            \n",
    "        _max = _max.max(dim=0).values     \n",
    "        _min = _min.min(dim=0).values\n",
    "               \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        models_range[_id] = {\"min\":_min.tolist(), \"max\": _max.tolist()}\n",
    "        \n",
    "        print(\"model\", _id, \"max\", _max.tolist(), \"min\", _min.tolist())\n",
    "            \n",
    "        max = torch.cat((max, _max.unsqueeze(0)), dim=0)\n",
    "        min = torch.cat((min, _min.unsqueeze(0)), dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pctbsiqi': {'min': [-1.3958884477615356,\n",
       "   -0.6594092845916748,\n",
       "   -1.3863295316696167,\n",
       "   0.00026616296963766217],\n",
       "  'max': [1.6746190786361694,\n",
       "   0.07133796066045761,\n",
       "   1.26933753490448,\n",
       "   0.0012228247942402959]},\n",
       " 'o8jxyrj5': {'min': [-1.8232892751693726,\n",
       "   -1.7502270936965942,\n",
       "   -1.6060312986373901,\n",
       "   -0.9402924180030823],\n",
       "  'max': [1.6372580528259277,\n",
       "   1.747969150543213,\n",
       "   1.2924197912216187,\n",
       "   1.519474744796753]},\n",
       " 'ymdetlr8': {'min': [-1.5534520149230957,\n",
       "   -0.07537082582712173,\n",
       "   -1.4862853288650513,\n",
       "   -0.9302182793617249],\n",
       "  'max': [1.31331467628479,\n",
       "   0.7224118113517761,\n",
       "   1.5972239971160889,\n",
       "   0.1701325923204422]},\n",
       " 'i4wfl4b4': {'min': [-1.1120800971984863,\n",
       "   -0.9972944855690002,\n",
       "   -0.5565490126609802,\n",
       "   -0.45933181047439575],\n",
       "  'max': [1.6199065446853638,\n",
       "   1.3801569938659668,\n",
       "   0.013666436076164246,\n",
       "   1.355510950088501]},\n",
       " 'vyfy7lha': {'min': [-1.6668015718460083,\n",
       "   -0.0009262582170777023,\n",
       "   -1.7075635194778442,\n",
       "   -1.8518742322921753],\n",
       "  'max': [0.9865561723709106,\n",
       "   0.23190835118293762,\n",
       "   0.9161754250526428,\n",
       "   0.9468040466308594]},\n",
       " '7aziw3nx': {'min': [-1.541772723197937,\n",
       "   -0.008815288543701172,\n",
       "   -1.234311580657959,\n",
       "   -1.7204748392105103],\n",
       "  'max': [1.1772940158843994,\n",
       "   0.2203264832496643,\n",
       "   0.32889503240585327,\n",
       "   1.2360318899154663]},\n",
       " '6cj4c36w': {'min': [-0.8825191259384155,\n",
       "   -0.05352480709552765,\n",
       "   -1.6310874223709106,\n",
       "   -1.7323819398880005],\n",
       "  'max': [0.21104083955287933,\n",
       "   0.8396482467651367,\n",
       "   1.3574613332748413,\n",
       "   1.3282206058502197]},\n",
       " '8d2mwki4': {'min': [-0.90981525182724,\n",
       "   -0.8965160250663757,\n",
       "   -0.856239914894104,\n",
       "   -0.350905179977417],\n",
       "  'max': [1.726462960243225,\n",
       "   1.7417572736740112,\n",
       "   1.6043498516082764,\n",
       "   0.0006538935122080147]},\n",
       " 'siflj6dk': {'min': [-0.06503783166408539,\n",
       "   -1.9445329904556274,\n",
       "   -0.0006112190894782543,\n",
       "   -1.7431806325912476],\n",
       "  'max': [0.6747777462005615,\n",
       "   1.5505409240722656,\n",
       "   -4.904134766547941e-05,\n",
       "   1.653831958770752]},\n",
       " 'omaoac63': {'min': [-1.8376109600067139,\n",
       "   -0.9383289217948914,\n",
       "   -1.7438448667526245,\n",
       "   -0.11638431996107101],\n",
       "  'max': [1.6803079843521118,\n",
       "   0.12739428877830505,\n",
       "   1.9200400114059448,\n",
       "   0.8957136869430542]},\n",
       " 'senl8hn1': {'min': [-1.7098701000213623,\n",
       "   -1.7187159061431885,\n",
       "   -1.7076935768127441,\n",
       "   -1.7145898342132568],\n",
       "  'max': [1.1382828950881958,\n",
       "   1.7197128534317017,\n",
       "   1.6995105743408203,\n",
       "   1.720637321472168]},\n",
       " 'fc4x5bsx': {'min': [-1.6599247455596924,\n",
       "   -1.0748488903045654,\n",
       "   0.32284682989120483,\n",
       "   -1.034473180770874],\n",
       "  'max': [0.15479649603366852,\n",
       "   1.2426408529281616,\n",
       "   1.715172290802002,\n",
       "   0.18656404316425323]},\n",
       " '746wz0w1': {'min': [-1.5528682470321655,\n",
       "   -1.0895296335220337,\n",
       "   -1.1399810314178467,\n",
       "   -1.6288503408432007],\n",
       "  'max': [-0.04332290217280388,\n",
       "   1.5731030702590942,\n",
       "   1.6169477701187134,\n",
       "   1.6142486333847046]},\n",
       " '9b9pjlgs': {'min': [-1.2025809288024902,\n",
       "   -1.4607346057891846,\n",
       "   -1.5762684345245361,\n",
       "   -0.8785410523414612],\n",
       "  'max': [0.7907081842422485,\n",
       "   0.9646182656288147,\n",
       "   1.136832594871521,\n",
       "   0.584116518497467]},\n",
       " '2swzga0k': {'min': [-1.3454747200012207,\n",
       "   -1.053367257118225,\n",
       "   -1.2270889282226562,\n",
       "   -0.44327738881111145],\n",
       "  'max': [0.7010164856910706,\n",
       "   0.6740905046463013,\n",
       "   0.8112685084342957,\n",
       "   0.43762096762657166]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/trained/transformer-autoencoder-jan/models_range.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/json/__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "with open(\"models/trained/transformer-autoencoder-jan/models_range.json\", \"wb\") as f:\n",
    "    json.dump(models_range, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faab-uzUOpGyK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
